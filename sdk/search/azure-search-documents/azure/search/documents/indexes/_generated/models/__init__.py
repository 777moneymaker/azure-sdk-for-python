# coding=utf-8
# --------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for license information.
# Code generated by Microsoft (R) Python Code Generator.
# Changes may cause incorrect behavior and will be lost if the code is regenerated.
# --------------------------------------------------------------------------

from ._models import AnalyzeRequest
from ._models import AnalyzeResult
from ._models import AnalyzedTokenInfo
from ._models import AsciiFoldingTokenFilter
from ._models import AzureActiveDirectoryApplicationCredentials
from ._models import AzureOpenAIEmbeddingSkill
from ._models import AzureOpenAIVectorizer
from ._models import AzureOpenAIVectorizerParameters
from ._models import BM25SimilarityAlgorithm
from ._models import BinaryQuantizationCompression
from ._models import CharFilter
from ._models import CjkBigramTokenFilter
from ._models import ClassicSimilarityAlgorithm
from ._models import ClassicTokenizer
from ._models import CognitiveServicesAccount
from ._models import CognitiveServicesAccountKey
from ._models import CommonGramTokenFilter
from ._models import ConditionalSkill
from ._models import CorsOptions
from ._models import CustomAnalyzer
from ._models import CustomEntity
from ._models import CustomEntityAlias
from ._models import CustomEntityLookupSkill
from ._models import DataChangeDetectionPolicy
from ._models import DataDeletionDetectionPolicy
from ._models import DataSourceCredentials
from ._models import DefaultCognitiveServicesAccount
from ._models import DictionaryDecompounderTokenFilter
from ._models import DistanceScoringFunction
from ._models import DistanceScoringParameters
from ._models import DocumentExtractionSkill
from ._models import EdgeNGramTokenFilter
from ._models import EdgeNGramTokenFilterV2
from ._models import EdgeNGramTokenizer
from ._models import ElisionTokenFilter
from ._models import EntityLinkingSkill
from ._models import EntityRecognitionSkill
from ._models import EntityRecognitionSkillV3
from ._models import ExhaustiveKnnAlgorithmConfiguration
from ._models import ExhaustiveKnnParameters
from ._models import FieldMapping
from ._models import FieldMappingFunction
from ._models import FreshnessScoringFunction
from ._models import FreshnessScoringParameters
from ._models import GetIndexStatisticsResult
from ._models import HighWaterMarkChangeDetectionPolicy
from ._models import HnswAlgorithmConfiguration
from ._models import HnswParameters
from ._models import ImageAnalysisSkill
from ._models import IndexerExecutionResult
from ._models import IndexingParameters
from ._models import IndexingParametersConfiguration
from ._models import IndexingSchedule
from ._models import InputFieldMappingEntry
from ._models import KeepTokenFilter
from ._models import KeyPhraseExtractionSkill
from ._models import KeywordMarkerTokenFilter
from ._models import KeywordTokenizer
from ._models import KeywordTokenizerV2
from ._models import LanguageDetectionSkill
from ._models import LengthTokenFilter
from ._models import LexicalAnalyzer
from ._models import LexicalTokenizer
from ._models import LimitTokenFilter
from ._models import ListDataSourcesResult
from ._models import ListIndexersResult
from ._models import ListSkillsetsResult
from ._models import ListSynonymMapsResult
from ._models import LuceneStandardAnalyzer
from ._models import LuceneStandardTokenizer
from ._models import LuceneStandardTokenizerV2
from ._models import MagnitudeScoringFunction
from ._models import MagnitudeScoringParameters
from ._models import MappingCharFilter
from ._models import MergeSkill
from ._models import MicrosoftLanguageStemmingTokenizer
from ._models import MicrosoftLanguageTokenizer
from ._models import NGramTokenFilter
from ._models import NGramTokenFilterV2
from ._models import NGramTokenizer
from ._models import OcrSkill
from ._models import OutputFieldMappingEntry
from ._models import PIIDetectionSkill
from ._models import PathHierarchyTokenizerV2
from ._models import PatternAnalyzer
from ._models import PatternCaptureTokenFilter
from ._models import PatternReplaceCharFilter
from ._models import PatternReplaceTokenFilter
from ._models import PatternTokenizer
from ._models import PhoneticTokenFilter
from ._models import ResourceCounter
from ._models import ScalarQuantizationCompression
from ._models import ScalarQuantizationParameters
from ._models import ScoringFunction
from ._models import ScoringProfile
from ._models import SearchField
from ._models import SearchIndex
from ._models import SearchIndexer
from ._models import SearchIndexerDataContainer
from ._models import SearchIndexerDataIdentity
from ._models import SearchIndexerDataNoneIdentity
from ._models import SearchIndexerDataSource
from ._models import SearchIndexerDataUserAssignedIdentity
from ._models import SearchIndexerError
from ._models import SearchIndexerIndexProjection
from ._models import SearchIndexerIndexProjectionSelector
from ._models import SearchIndexerIndexProjectionsParameters
from ._models import SearchIndexerKnowledgeStore
from ._models import SearchIndexerKnowledgeStoreBlobProjectionSelector
from ._models import SearchIndexerKnowledgeStoreFileProjectionSelector
from ._models import SearchIndexerKnowledgeStoreObjectProjectionSelector
from ._models import SearchIndexerKnowledgeStoreProjection
from ._models import SearchIndexerKnowledgeStoreProjectionSelector
from ._models import SearchIndexerKnowledgeStoreTableProjectionSelector
from ._models import SearchIndexerLimits
from ._models import SearchIndexerSkill
from ._models import SearchIndexerSkillset
from ._models import SearchIndexerStatus
from ._models import SearchIndexerWarning
from ._models import SearchResourceEncryptionKey
from ._models import SearchServiceCounters
from ._models import SearchServiceLimits
from ._models import SearchServiceStatistics
from ._models import SearchSuggester
from ._models import SemanticConfiguration
from ._models import SemanticField
from ._models import SemanticPrioritizedFields
from ._models import SemanticSearch
from ._models import SentimentSkill
from ._models import SentimentSkillV3
from ._models import ShaperSkill
from ._models import ShingleTokenFilter
from ._models import SimilarityAlgorithm
from ._models import SnowballTokenFilter
from ._models import SoftDeleteColumnDeletionDetectionPolicy
from ._models import SplitSkill
from ._models import SqlIntegratedChangeTrackingPolicy
from ._models import StemmerOverrideTokenFilter
from ._models import StemmerTokenFilter
from ._models import StopAnalyzer
from ._models import StopwordsTokenFilter
from ._models import SynonymMap
from ._models import SynonymTokenFilter
from ._models import TagScoringFunction
from ._models import TagScoringParameters
from ._models import TextTranslationSkill
from ._models import TextWeights
from ._models import TokenFilter
from ._models import TruncateTokenFilter
from ._models import UaxUrlEmailTokenizer
from ._models import UniqueTokenFilter
from ._models import VectorSearch
from ._models import VectorSearchAlgorithmConfiguration
from ._models import VectorSearchCompression
from ._models import VectorSearchProfile
from ._models import VectorSearchVectorizer
from ._models import WebApiSkill
from ._models import WebApiVectorizer
from ._models import WebApiVectorizerParameters
from ._models import WordDelimiterTokenFilter

from ._enums import AzureOpenAIModelName
from ._enums import BlobIndexerDataToExtract
from ._enums import BlobIndexerImageAction
from ._enums import BlobIndexerPDFTextRotationAlgorithm
from ._enums import BlobIndexerParsingMode
from ._enums import CharFilterName
from ._enums import CjkBigramTokenFilterScripts
from ._enums import CustomEntityLookupSkillLanguage
from ._enums import EdgeNGramTokenFilterSide
from ._enums import EntityCategory
from ._enums import EntityRecognitionSkillLanguage
from ._enums import Enum0
from ._enums import ImageAnalysisSkillLanguage
from ._enums import ImageDetail
from ._enums import IndexProjectionMode
from ._enums import IndexerExecutionEnvironment
from ._enums import IndexerExecutionStatus
from ._enums import IndexerStatus
from ._enums import KeyPhraseExtractionSkillLanguage
from ._enums import LexicalAnalyzerName
from ._enums import LexicalTokenizerName
from ._enums import MicrosoftStemmingTokenizerLanguage
from ._enums import MicrosoftTokenizerLanguage
from ._enums import OcrLineEnding
from ._enums import OcrSkillLanguage
from ._enums import PIIDetectionSkillMaskingMode
from ._enums import PhoneticEncoder
from ._enums import RegexFlags
from ._enums import ScoringFunctionAggregation
from ._enums import ScoringFunctionInterpolation
from ._enums import SearchFieldDataType
from ._enums import SearchIndexerDataSourceType
from ._enums import SentimentSkillLanguage
from ._enums import SnowballTokenFilterLanguage
from ._enums import SplitSkillLanguage
from ._enums import StemmerTokenFilterLanguage
from ._enums import StopwordsList
from ._enums import TextSplitMode
from ._enums import TextTranslationSkillLanguage
from ._enums import TokenCharacterKind
from ._enums import TokenFilterName
from ._enums import VectorEncodingFormat
from ._enums import VectorSearchAlgorithmKind
from ._enums import VectorSearchAlgorithmMetric
from ._enums import VectorSearchCompressionTarget
from ._enums import VectorSearchVectorizerKind
from ._enums import VisualFeature
from ._patch import __all__ as _patch_all
from ._patch import *  # pylint: disable=unused-wildcard-import
from ._patch import patch_sdk as _patch_sdk

__all__ = [
    "AnalyzeRequest",
    "AnalyzeResult",
    "AnalyzedTokenInfo",
    "AsciiFoldingTokenFilter",
    "AzureActiveDirectoryApplicationCredentials",
    "AzureOpenAIEmbeddingSkill",
    "AzureOpenAIVectorizer",
    "AzureOpenAIVectorizerParameters",
    "BM25SimilarityAlgorithm",
    "BinaryQuantizationCompression",
    "CharFilter",
    "CjkBigramTokenFilter",
    "ClassicSimilarityAlgorithm",
    "ClassicTokenizer",
    "CognitiveServicesAccount",
    "CognitiveServicesAccountKey",
    "CommonGramTokenFilter",
    "ConditionalSkill",
    "CorsOptions",
    "CustomAnalyzer",
    "CustomEntity",
    "CustomEntityAlias",
    "CustomEntityLookupSkill",
    "DataChangeDetectionPolicy",
    "DataDeletionDetectionPolicy",
    "DataSourceCredentials",
    "DefaultCognitiveServicesAccount",
    "DictionaryDecompounderTokenFilter",
    "DistanceScoringFunction",
    "DistanceScoringParameters",
    "DocumentExtractionSkill",
    "EdgeNGramTokenFilter",
    "EdgeNGramTokenFilterV2",
    "EdgeNGramTokenizer",
    "ElisionTokenFilter",
    "EntityLinkingSkill",
    "EntityRecognitionSkill",
    "EntityRecognitionSkillV3",
    "ExhaustiveKnnAlgorithmConfiguration",
    "ExhaustiveKnnParameters",
    "FieldMapping",
    "FieldMappingFunction",
    "FreshnessScoringFunction",
    "FreshnessScoringParameters",
    "GetIndexStatisticsResult",
    "HighWaterMarkChangeDetectionPolicy",
    "HnswAlgorithmConfiguration",
    "HnswParameters",
    "ImageAnalysisSkill",
    "IndexerExecutionResult",
    "IndexingParameters",
    "IndexingParametersConfiguration",
    "IndexingSchedule",
    "InputFieldMappingEntry",
    "KeepTokenFilter",
    "KeyPhraseExtractionSkill",
    "KeywordMarkerTokenFilter",
    "KeywordTokenizer",
    "KeywordTokenizerV2",
    "LanguageDetectionSkill",
    "LengthTokenFilter",
    "LexicalAnalyzer",
    "LexicalTokenizer",
    "LimitTokenFilter",
    "ListDataSourcesResult",
    "ListIndexersResult",
    "ListSkillsetsResult",
    "ListSynonymMapsResult",
    "LuceneStandardAnalyzer",
    "LuceneStandardTokenizer",
    "LuceneStandardTokenizerV2",
    "MagnitudeScoringFunction",
    "MagnitudeScoringParameters",
    "MappingCharFilter",
    "MergeSkill",
    "MicrosoftLanguageStemmingTokenizer",
    "MicrosoftLanguageTokenizer",
    "NGramTokenFilter",
    "NGramTokenFilterV2",
    "NGramTokenizer",
    "OcrSkill",
    "OutputFieldMappingEntry",
    "PIIDetectionSkill",
    "PathHierarchyTokenizerV2",
    "PatternAnalyzer",
    "PatternCaptureTokenFilter",
    "PatternReplaceCharFilter",
    "PatternReplaceTokenFilter",
    "PatternTokenizer",
    "PhoneticTokenFilter",
    "ResourceCounter",
    "ScalarQuantizationCompression",
    "ScalarQuantizationParameters",
    "ScoringFunction",
    "ScoringProfile",
    "SearchField",
    "SearchIndex",
    "SearchIndexer",
    "SearchIndexerDataContainer",
    "SearchIndexerDataIdentity",
    "SearchIndexerDataNoneIdentity",
    "SearchIndexerDataSource",
    "SearchIndexerDataUserAssignedIdentity",
    "SearchIndexerError",
    "SearchIndexerIndexProjection",
    "SearchIndexerIndexProjectionSelector",
    "SearchIndexerIndexProjectionsParameters",
    "SearchIndexerKnowledgeStore",
    "SearchIndexerKnowledgeStoreBlobProjectionSelector",
    "SearchIndexerKnowledgeStoreFileProjectionSelector",
    "SearchIndexerKnowledgeStoreObjectProjectionSelector",
    "SearchIndexerKnowledgeStoreProjection",
    "SearchIndexerKnowledgeStoreProjectionSelector",
    "SearchIndexerKnowledgeStoreTableProjectionSelector",
    "SearchIndexerLimits",
    "SearchIndexerSkill",
    "SearchIndexerSkillset",
    "SearchIndexerStatus",
    "SearchIndexerWarning",
    "SearchResourceEncryptionKey",
    "SearchServiceCounters",
    "SearchServiceLimits",
    "SearchServiceStatistics",
    "SearchSuggester",
    "SemanticConfiguration",
    "SemanticField",
    "SemanticPrioritizedFields",
    "SemanticSearch",
    "SentimentSkill",
    "SentimentSkillV3",
    "ShaperSkill",
    "ShingleTokenFilter",
    "SimilarityAlgorithm",
    "SnowballTokenFilter",
    "SoftDeleteColumnDeletionDetectionPolicy",
    "SplitSkill",
    "SqlIntegratedChangeTrackingPolicy",
    "StemmerOverrideTokenFilter",
    "StemmerTokenFilter",
    "StopAnalyzer",
    "StopwordsTokenFilter",
    "SynonymMap",
    "SynonymTokenFilter",
    "TagScoringFunction",
    "TagScoringParameters",
    "TextTranslationSkill",
    "TextWeights",
    "TokenFilter",
    "TruncateTokenFilter",
    "UaxUrlEmailTokenizer",
    "UniqueTokenFilter",
    "VectorSearch",
    "VectorSearchAlgorithmConfiguration",
    "VectorSearchCompression",
    "VectorSearchProfile",
    "VectorSearchVectorizer",
    "WebApiSkill",
    "WebApiVectorizer",
    "WebApiVectorizerParameters",
    "WordDelimiterTokenFilter",
    "AzureOpenAIModelName",
    "BlobIndexerDataToExtract",
    "BlobIndexerImageAction",
    "BlobIndexerPDFTextRotationAlgorithm",
    "BlobIndexerParsingMode",
    "CharFilterName",
    "CjkBigramTokenFilterScripts",
    "CustomEntityLookupSkillLanguage",
    "EdgeNGramTokenFilterSide",
    "EntityCategory",
    "EntityRecognitionSkillLanguage",
    "Enum0",
    "ImageAnalysisSkillLanguage",
    "ImageDetail",
    "IndexProjectionMode",
    "IndexerExecutionEnvironment",
    "IndexerExecutionStatus",
    "IndexerStatus",
    "KeyPhraseExtractionSkillLanguage",
    "LexicalAnalyzerName",
    "LexicalTokenizerName",
    "MicrosoftStemmingTokenizerLanguage",
    "MicrosoftTokenizerLanguage",
    "OcrLineEnding",
    "OcrSkillLanguage",
    "PIIDetectionSkillMaskingMode",
    "PhoneticEncoder",
    "RegexFlags",
    "ScoringFunctionAggregation",
    "ScoringFunctionInterpolation",
    "SearchFieldDataType",
    "SearchIndexerDataSourceType",
    "SentimentSkillLanguage",
    "SnowballTokenFilterLanguage",
    "SplitSkillLanguage",
    "StemmerTokenFilterLanguage",
    "StopwordsList",
    "TextSplitMode",
    "TextTranslationSkillLanguage",
    "TokenCharacterKind",
    "TokenFilterName",
    "VectorEncodingFormat",
    "VectorSearchAlgorithmKind",
    "VectorSearchAlgorithmMetric",
    "VectorSearchCompressionTarget",
    "VectorSearchVectorizerKind",
    "VisualFeature",
]
__all__.extend([p for p in _patch_all if p not in __all__])
_patch_sdk()
